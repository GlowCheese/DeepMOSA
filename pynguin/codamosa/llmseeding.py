from __future__ import annotations

import os
import ast
import inspect
import datetime
from typing import (
    Optional, Sequence, Set, Tuple,
    Callable, Dict, List, TYPE_CHECKING
)
from vendor.custom_logger import getLogger

from pynguin.globl import Globl
from pynguin.seeding import StatementDeserializer
from pynguin.utils import randomness
from pynguin.stmt import ASTAssignStatement
from pynguin.runtimevar import RuntimeVariable
from pynguin.config import TestCaseContext
from pynguin.config import AssertionGenerator
from pynguin.report import get_coverage_report
from pynguin.seeding import AstToTestCaseVisitor
from pynguin.export.pytestexporter import PyTestExporter
from pynguin.generic import GenericCallableAccessibleObject

from pynguin.codamosa.outputfixers import fixup_imports

if TYPE_CHECKING:
    import pynguin.testcase.testcase as tc
    import pynguin.ga.testsuitechromosome as tsc
    import pynguin.testcase.defaulttestcase as dtc
    
    from pynguin.setup import TestCluster
    from pynguin.execution import TestCaseExecutor
    from pynguin.codamosa.model import CodaMOSALanguageModel
    

logger = getLogger(__name__)


class NoCallableAccessibleObject(Exception):
    pass

def deserialize_code_to_testcases(
    test_file_contents: str,
    test_cluster: TestCluster,
    use_uninterpreted_statements: bool = False,
) -> Tuple[List[dtc.DefaultTestCase], int, int]:
    """Extracts as many TestCase objects as possible from the given code.

    Args:
        test_file_contents: code containing tests
        test_cluster: the TestCluster to deserialize with
        use_uninterpreted_statements: whether or not to allow ASTAssignStatements

    Returns:
        A tuple consisting of (1) a list of TestCase extracted from the given code
        (2) the number of parsable statements in the given code (3) the number
        of successfully parsed statements from that code
    """
    visitor = AstToTestCaseVisitor(
        include_nontest_functions=False,
        statement_deserializer=StatementDeserializer(
            test_cluster,
            use_uninterpreted_statements
        )
    )
    visitor.visit(ast.parse(test_file_contents))
    return (
        visitor.testcases,
        visitor.total_parsed_statements,
        visitor.total_statements,
    )

class CodaMOSASeeding:
    """Class for seeding the initial population with test cases generated by a large
    language model."""

    def __init__(self, test_cluster: TestCluster):
        self._prompt_gaos: Optional[Dict[GenericCallableAccessibleObject, int]] = None
        self._sample_with_replacement: bool = True
        self._max_samples_per_prompt: int = 1
        self._parsed_statements = 0
        self._parsable_statements = 0
        self._uninterp_statements = 0
        self._test_cluster = test_cluster

    @property
    def model(self) -> CodaMOSALanguageModel:
        """Provides the model wrapper object we query from

        Returns:
            The large language model wrapper
        """
        return self._model

    @model.setter
    def model(self, model: CodaMOSALanguageModel):
        self._model = model

    @property
    def executor(self) -> Optional[TestCaseExecutor]:
        """Provides the test executor.

        Returns:
            The test executor
        """
        return self._executor

    @executor.setter
    def executor(self, executor: Optional[TestCaseExecutor]):
        self._executor = executor

    @property
    def sample_with_replacement(self) -> bool:
        """Provides whether sampling with replacement is performed.

        Returns:
            Whether sampling with replacement is performed
        """
        return self._sample_with_replacement

    @sample_with_replacement.setter
    def sample_with_replacement(self, sample_with_replacement: bool):
        self._sample_with_replacement = sample_with_replacement

    @property
    def seeded_testcase(self) -> Optional[tc.TestCase]:
        """
        Generate a new test case. Prompt the language model with a generic accessible
        object to test.

        Returns:
            A new generated test case, or None if a test case could not be parsed
        """
        assert self._prompt_gaos is not None
        assert len(self._prompt_gaos) > 0
        prompt_gao = randomness.choice(list(self._prompt_gaos.keys()))
        if not self._sample_with_replacement:
            self._prompt_gaos[prompt_gao] -= 1
            if self._prompt_gaos[prompt_gao] == 0:
                self._prompt_gaos.pop(prompt_gao)
        testcases = self._get_targeted_testcase(prompt_gao)
        if len(testcases) > 0:
            return testcases[0]
        return None

    def get_random_targeted_testcase(self) -> Sequence[tc.TestCase]:
        """
        Generate a new test case (or multiple) aimed at a gao to be selected randomly

        Returns:
            A sequence of generated test cases
        """

        if self._prompt_gaos is None:
            self._setup_gaos()
            assert self._prompt_gaos is not None
        prompt_gao = randomness.choice(list(self._prompt_gaos.keys()))
        return self._get_targeted_testcase(prompt_gao)

    def _get_targeted_testcase(
        self, prompt_gao: GenericCallableAccessibleObject, context=""
    ) -> Sequence[tc.TestCase]:
        """
        Generate a new test case aimed at prompt_gao

        Args:
            prompt_gao: the GenericCallableAccessibleObject to target
            context: any additional context to pass

        Returns:
            A sequence of generated test cases
        """
        str_test_case = self._model.target_test_case(prompt_gao, context=context)
        use_uninterp_tuple = Globl.seeding_conf.uninterpreted_statements.value
        ret_testcases: Set[tc.TestCase] = set()
        for use_uninterp in use_uninterp_tuple:
            logger.debug("Codex-generated testcase:\n%s", str_test_case)
            (
                testcases,
                parsed_statements,
                parsable_statements,
            ) = deserialize_code_to_testcases(str_test_case, self._test_cluster, use_uninterp)
            for testcase in testcases:
                exporter = PyTestExporter(wrap_code=False)
                testcase_str = exporter.export_sequences_to_str([testcase])
                logger.debug(
                    "Imported test case (%i/%i statements parsed):\n %s",
                    parsed_statements, parsable_statements, testcase_str
                )

                with open(
                    os.path.join(Globl.report_dir, "gen_after_parse.py"),
                    "a+", encoding="UTF-8",
                ) as log_file:
                    log_file.write(f"\n\n# ({Globl.module_name}) Generated at {datetime.datetime.now()}\n")
                    log_file.write(testcase_str)

                self._parsable_statements += parsable_statements
                self._parsed_statements += parsed_statements
                self._uninterp_statements += len(
                    [
                        stmt
                        for stmt in testcase.statements
                        if isinstance(stmt, ASTAssignStatement)
                    ]
                )

                stat = Globl.statistics_tracker
                stat.track_output_variable(
                    RuntimeVariable.ParsableStatements, self._parsable_statements
                )
                stat.track_output_variable(
                    RuntimeVariable.ParsedStatements, self._parsed_statements
                )
                stat.track_output_variable(
                    RuntimeVariable.UninterpStatements, self._uninterp_statements
                )
            ret_testcases.update(testcases)
        return list(ret_testcases)

    @property
    def has_tests(self) -> bool:
        """Whether or not test cases are left to generate

        Returns:
            Whether or not test cases have been found
        """
        if self._prompt_gaos is None:
            self._setup_gaos()
            assert self._prompt_gaos is not None
        return len(self._prompt_gaos) > 0

    def _setup_gaos(self):
        """Sets up the prompt gaos if they are unset."""
        self._prompt_gaos = {
            gao: self._max_samples_per_prompt  # type: ignore
            for gao in Globl.test_cluster.accessible_objects_under_test
            if issubclass(type(gao), GenericCallableAccessibleObject)
        }

    def target_uncovered_functions(
        self,
        test_suite: tsc.TestSuiteChromosome,
        num_samples: int,
        resources_left: Callable[[], bool],
    ) -> List[tc.TestCase]:

        # pylint: disable=R0914,R0912
        """Generate test cases for functions that are less covered by `test_suite`

        Args:
            test_suite: current best test suite
            num_samples: number of test cases to sample
            resources_left: a callable that returns true if there are resources left
                in the search algorithm

        Returns:
            a list of Codex-generated test cases.
        """
        assert self.executor is not None
        if self._prompt_gaos is None:
            self._setup_gaos()
            assert self._prompt_gaos is not None

        line_annotations = get_coverage_report(
            self.executor.tracer,
            test_suite,
            Globl.coverage_metrics
        ).line_annotations

        def coverage_in_range(start_line: int, end_line: int) -> Tuple[int, int]:
            """Helper coverage to determine the coverage of consecutive lines.

            Args:
                start_line: first line to consider, inclusive
                end_line: last line to consider, inclusive

            Returns:
                the total number of covered elements (branches, lines) in the line
                range, as well as the total number of coverable elements in that range.
            """
            total_coverage_points = 0
            covered_coverage_points = 0
            for line_annot in line_annotations:
                if start_line <= line_annot.line_no <= end_line:
                    total_coverage_points += line_annot.total.existing
                    covered_coverage_points += line_annot.total.covered
            return covered_coverage_points, total_coverage_points

        ordered_gaos: List[GenericCallableAccessibleObject] = []
        ordered_selection_probabilities: List[float] = []

        for gao in self._prompt_gaos.keys():
            if isinstance(gao, GenericCallableAccessibleObject):
                ordered_gaos.append(gao)
                try:
                    source_lines, start_line = inspect.getsourcelines(gao.callable)
                    covered, total = coverage_in_range(
                        start_line, start_line + len(source_lines) - 1
                    )
                    if total > 0:
                        ordered_selection_probabilities.append(1 - (covered / total))
                    else:
                        ordered_selection_probabilities.append(0)
                except (TypeError, OSError):
                    ordered_selection_probabilities.append(0)

        denominator = sum(ordered_selection_probabilities)
        if denominator == 0:
            # All the top-level callable functions are fully covered. I guess
            # just do some random sampling?
            ordered_selection_probabilities = [
                1 / len(ordered_selection_probabilities)
            ] * len(ordered_selection_probabilities)
        else:
            ordered_selection_probabilities = [
                p / denominator for p in ordered_selection_probabilities
            ]

        if Globl.conf.codamosa.test_case_context in (
            TestCaseContext.SMALLEST,
            TestCaseContext.RANDOM,
        ):
            exporter = PyTestExporter(wrap_code=False)
            ctx_test_cases = [
                (
                    fixup_imports(exporter.export_sequences_to_str([tcc.test_case])),
                    tcc.size(),
                )
                for tcc in test_suite.test_case_chromosomes
                if tcc.size() > 0
            ]
            ctx_test_cases.sort(key=lambda x: x[1])

        targeted_test_cases: List[tc.TestCase] = []
        for gao in randomness.choices(
            ordered_gaos, weights=ordered_selection_probabilities, k=num_samples
        ):
            if not resources_left():
                break
            if (
                Globl.conf.codamosa.test_case_context
                == TestCaseContext.SMALLEST
                and len(ctx_test_cases) > 0
            ):
                context = ctx_test_cases[0][0] + "\n\n"
            elif (
                Globl.conf.codamosa.test_case_context
                == TestCaseContext.RANDOM
                and len(ctx_test_cases) > 0
            ):
                context = randomness.choice(ctx_test_cases)[0] + "\n\n"
            else:
                context = ""
            test_cases = self._get_targeted_testcase(gao, context)
            targeted_test_cases.extend(test_cases)
        return targeted_test_cases